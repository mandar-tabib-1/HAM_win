{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To be used for inference purpose "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Inference for momentum and pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gputrue=False\n",
    "# Use CPU\n",
    "if gputrue==True:\n",
    "    \n",
    "    with tf.device('/CPU:0'):\n",
    "        cpu_tensor = tf.constant(1.0)\n",
    "else:\n",
    "# Use GPU (if available)\n",
    "    with tf.device('/GPU:0'):\n",
    "        gpu_tensor = tf.constant(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get CPU memory usage\n",
    "\n",
    "def get_cpu_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss  # in bytes\n",
    "\n",
    "# Function to get GPU memory usage using nvidia-smi\n",
    "def get_gpu_memory_usage():\n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ])\n",
    "    return int(result.split()[0])  # in MB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import joblib #Version: 1.2.0\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error #scikit-learn              1.3.0 \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 26})\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "print(torch.cuda.is_available())  # Returns True if a GPU is available\n",
    "# print(torch.cuda.current_device())  # Returns the index of the current GPU\n",
    "# print(torch.cuda.get_device_name(0))  # Returns the name of the GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "current_dir = os.getcwd()    # Get the current directory. \n",
    "sys.path.append(current_dir) # Append to path \n",
    "fn2=os.path.join(current_dir,'..','SourceCode')\n",
    "sys.path.append(fn2)         # Add the path to the folder containing imports.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "import subprocess\n",
    "import imports_kpn as kpn\n",
    "\n",
    "\n",
    "# Select device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the model\n",
    "\n",
    "model = torch.load('lstm_model_best.pth')\n",
    "\n",
    "# Move the model to the appropriate device (CPU/GPU)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model.to(device)\n",
    "\n",
    "# Restrict TensorFlow to only use the GPU\n",
    "# Function to set CPU as the visible device\n",
    "def use_cpu():\n",
    "    tf.config.set_visible_devices([], 'GPU') #Hide GPU from visible devices\n",
    "\n",
    "# Function to set GPU as the visible device\n",
    "def use_gpu():\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # For ANN, For lstm use imports_kpn\n",
    "   \n",
    "        \n",
    "# import tensorflow as tf  # version 2.6.0\n",
    "\n",
    "\n",
    "\n",
    "def scale_3D_inference(data_test_features,normalizer_test):\n",
    "    \n",
    "    # Step: Reshape Test dataset to 2D\n",
    "    samples_test, timesteps_test, features_test = data_test_features.shape\n",
    "    data_test_features = data_test_features.reshape(-1, features_test) \n",
    "    \n",
    "    # Step: Scale features in test dataset         \n",
    "    norm_test_features=normalizer_test.transform(data_test_features)\n",
    "        \n",
    "    #print(normalizer_test.data_max_)\n",
    "    #print(normalizer_test.data_min_)\n",
    "    \n",
    "    # Step: Reshape back to 3D\n",
    "    norm_test_features = norm_test_features.reshape(samples_test, timesteps_test, features_test)\n",
    "    \n",
    "    return norm_test_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Give path locations to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum=True\n",
    "pressure=False\n",
    "allsamples=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if momentum==True:\n",
    "    dirFile='../Models/LSTM_HAM'  #ML model for momentum\n",
    " \n",
    "    dirFile_result='../Results'\n",
    "    # kpn.create_directory_if_not_exists(dirFile_result) \n",
    "     \n",
    "    filename_4_scalingfunction = dirFile + \"/Scaling.save\"\n",
    "    \n",
    "elif pressure==True:\n",
    "    dirFile='../Models/LSTM_HAM_Pressure'\n",
    "    # kpn.create_directory_if_not_exists(dirFile)\n",
    "   \n",
    "    dirFile_result='../Results_Pressure'\n",
    "    # kpn.create_directory_if_not_exists(dirFile_result)  \n",
    "    \n",
    "    filename_4_scalingfunction = dirFile + \"/Scaling.save\"\n",
    "else:\n",
    "    print('Please choose either momentum or pressure as true')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 3, 18) (20, 3, 18)\n",
      "CPU Memory usage before start: 219.85 MB\n",
      "GPU Memory usage before start: 1306 MB\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m norm_test_features\u001b[38;5;241m=\u001b[39mscale_3D_inference(test_data,normalizer) \u001b[38;5;66;03m# data_test_features \u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#Predict the residual using the model\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m addcorrection\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(norm_test_features) \u001b[38;5;66;03m#addcorrection shape : num_samples x num_modes\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputational time no loading, s\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start2)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "                 \n",
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "#Load model from path's location (momentum or pressure)\n",
    "#model=tf.keras.models.load_model(dirFile+'/best_model.h5')\n",
    "\n",
    "#Load unseen test dataset and scale it for inference.  \n",
    "    # CHECK : Test FEATURES data shape: num_samples (either 1 or all samples) x 3 x num_modes (num_modes=18 for momentum and 10 for pressure). \n",
    "    # Load scaling function for either momentum and pressure\n",
    "    \n",
    "    \n",
    "# Data path for pre-processed data\n",
    "datapath =\"../Data/Coefficient/\"\n",
    "\n",
    "# Data path for modeled data\n",
    "modelpathbase = \"../Data/Coefficient/\"\n",
    "\n",
    "# Data from measurement data\n",
    "A = kpn.np.load(datapath + 'A.npy') #Features for the momentum\n",
    "MomentumRes = kpn.np.load(datapath + 'MomentumRes.npy') #label for the momentum\n",
    "\n",
    "#Split of training and validation data.\n",
    "xtrain,xtest=kpn.split_timeseries_3D(A,nfrac=0.8)\n",
    "\n",
    "print(xtrain.shape,xtest.shape)\n",
    "\n",
    "ytrain,ytest=kpn.split_timeseries_3D(MomentumRes,nfrac=0.8)\n",
    "\n",
    "if allsamples==True: \n",
    "    test_data=xtrain # Load features dataset #[0,:,:].reshape(1,xtrain.shape[1],xtrain.shape[2])\n",
    "else:\n",
    "    test_data=xtrain[0,:,:].reshape(1,xtrain.shape[1],xtrain.shape[2])\n",
    "    \n",
    "print(f\"CPU Memory usage before start: {get_cpu_memory_usage() / (1024 ** 2):.2f} MB\")\n",
    "print(f\"GPU Memory usage before start: {get_gpu_memory_usage()} MB\")\n",
    "normalizer=joblib.load(filename_4_scalingfunction)\n",
    "model.eval()\n",
    "timely=[]\n",
    "start2 = time.process_time()\n",
    "num=1000\n",
    "\n",
    "\n",
    "\n",
    "# Run inference\n",
    "\n",
    "\n",
    "# Convert the outputs to numpy array if needed\n",
    "test_outputs = test_outputs.numpy()\n",
    "\n",
    "for i in range(num):       \n",
    "\n",
    "    norm_test_features=scale_3D_inference(test_data,normalizer) # data_test_features \n",
    "    # Convert test numpy array to PyTorch tensor\n",
    "    test_data_tensor = torch.tensor(norm_test_features, dtype=torch.float32)\n",
    "    #Predict the residual using the model\n",
    "    with torch.no_grad():\n",
    "        test_outputs = loaded_model(norm_test_features)\n",
    "    \n",
    "\n",
    "    print(time.process_time() - start)\n",
    "    print(\"Computational time no loading, s\", time.process_time() - start2)\n",
    "timely.append( time.process_time() - start2)      \n",
    "# #Plot the residual\n",
    "\n",
    "# Check memory usage and time\n",
    "print(f\"Mean Time: s, {(time.process_time() - start)/num}\")\n",
    "print(f\"CPU Memory usage: {get_cpu_memory_usage() / (1024 ** 2):.2f} MB\")\n",
    "print(f\"GPU Memory usage: {get_gpu_memory_usage()} MB\")\n",
    "\n",
    "\n",
    "print(norm_test_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpn.plt.hist(timely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpn.np.array(timely).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'\\\\)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(addcorrection.shape[1]):\n",
    "    plt.figure(figsize=(20,12))\n",
    "   \n",
    "    plt.plot(addcorrection[:,i],label='ML predicted')\n",
    "    \n",
    "    plt.title('Comparison plot')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    filename = f'Comparison plot_{i}.png'\n",
    "    \n",
    "    plt.savefig(os.path.abspath(dirFile_result+'/'+filename), dpi = 200)\n",
    "    \n",
    "    plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
