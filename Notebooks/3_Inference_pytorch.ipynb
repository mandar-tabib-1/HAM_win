{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To be used for inference purpose "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Inference for momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get CPU memory usage\n",
    "\n",
    "def get_cpu_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss  # in bytes\n",
    "\n",
    "# Function to get GPU memory usage using nvidia-smi\n",
    "def get_gpu_memory_usage():\n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ])\n",
    "    return int(result.split()[0])  # in MB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib #Version: 1.2.0\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error #scikit-learn              1.3.0 \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 26})\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from lstm_model_class import LSTMModel  # Import the model class\n",
    "\n",
    "from lstm_model_class import *\n",
    "\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())  # Returns True if a GPU is available\n",
    "# print(torch.cuda.current_device())  # Returns the index of the current GPU\n",
    "# print(torch.cuda.get_device_name(0))  # Returns the name of the GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "current_dir = os.getcwd()    # Get the current directory. \n",
    "sys.path.append(current_dir) # Append to path \n",
    "fn2=os.path.join(current_dir,'..','SourceCode')\n",
    "sys.path.append(fn2)         # Add the path to the folder containing imports.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "import subprocess\n",
    "import imports_kpn as kpn\n",
    "\n",
    "\n",
    "# Select device : CPU\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the model\n",
    "#loaded_model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "#loaded_model.load_state_dict(torch.load('lstm_model_best_pytorch.pth'))\n",
    "\n",
    "# Load the scripted model\n",
    "loaded_model = torch.jit.load('scripted_model_lstm_pytorch.pt')\n",
    "\n",
    "loaded_model.eval()\n",
    "#model = torch.load('lstm_model_best.pth')\n",
    "\n",
    "# Move the model to the appropriate device (CPU/GPU)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model.to(device)\n",
    "\n",
    "# Restrict TensorFlow to only use the GPU\n",
    "# Function to set CPU as the visible device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # For ANN, For lstm use imports_kpn\n",
    "   \n",
    "        \n",
    "# import tensorflow as tf  # version 2.6.0\n",
    "\n",
    "\n",
    "\n",
    "def scale_3D_inference(data_test_features,normalizer_test):\n",
    "    \n",
    "    # Step: Reshape Test dataset to 2D\n",
    "    samples_test, timesteps_test, features_test = data_test_features.shape\n",
    "    data_test_features = data_test_features.reshape(-1, features_test) \n",
    "    \n",
    "    # Step: Scale features in test dataset         \n",
    "    norm_test_features=normalizer_test.transform(data_test_features)\n",
    "        \n",
    "    #print(normalizer_test.data_max_)\n",
    "    #print(normalizer_test.data_min_)\n",
    "    \n",
    "    # Step: Reshape back to 3D\n",
    "    norm_test_features = norm_test_features.reshape(samples_test, timesteps_test, features_test)\n",
    "    \n",
    "    return norm_test_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Give path locations to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum=True\n",
    "pressure=False\n",
    "allsamples=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if momentum==True:\n",
    "    dirFile='../Models/LSTM_HAM'  #ML model for momentum\n",
    " \n",
    "    dirFile_result='../Results'\n",
    "    # kpn.create_directory_if_not_exists(dirFile_result) \n",
    "     \n",
    "    filename_4_scalingfunction = dirFile + \"/Scaling.save\"\n",
    "    \n",
    "elif pressure==True:\n",
    "    dirFile='../Models/LSTM_HAM_Pressure'\n",
    "    # kpn.create_directory_if_not_exists(dirFile)\n",
    "   \n",
    "    dirFile_result='../Results_Pressure'\n",
    "    # kpn.create_directory_if_not_exists(dirFile_result)  \n",
    "    \n",
    "    filename_4_scalingfunction = dirFile + \"/Scaling.save\"\n",
    "else:\n",
    "    print('Please choose either momentum or pressure as true')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "                 \n",
    "import time\n",
    "start = time.process_time()\n",
    "   \n",
    "    \n",
    "# Data path for pre-processed data\n",
    "datapath =\"../Data/Coefficient/\"\n",
    "\n",
    "# Data path for modeled data\n",
    "modelpathbase = \"../Data/Coefficient/\"\n",
    "\n",
    "# Data from measurement data\n",
    "A = kpn.np.load(datapath + 'A.npy') #Features for the momentum\n",
    "MomentumRes = kpn.np.load(datapath + 'MomentumRes.npy') #label for the momentum\n",
    "\n",
    "#Split of training and validation data.\n",
    "xtrain,xtest=kpn.split_timeseries_3D(A,nfrac=0.8)\n",
    "\n",
    "print(xtrain.shape,xtest.shape)\n",
    "\n",
    "ytrain,ytest=kpn.split_timeseries_3D(MomentumRes,nfrac=0.8)\n",
    "\n",
    "if allsamples==True: \n",
    "    test_data=xtrain # Load features dataset #[0,:,:].reshape(1,xtrain.shape[1],xtrain.shape[2])\n",
    "    print(f\"Test data shape: , {test_data.shape}\")\n",
    "else:\n",
    "    test_data=xtrain[0,:,:].reshape(1,xtrain.shape[1],xtrain.shape[2])\n",
    "    print(f\"Test data shape: , {test_data.shape}\")\n",
    "    \n",
    "print(f\"CPU Memory usage before start: {get_cpu_memory_usage() / (1024 ** 2):.2f} MB\")\n",
    "print(f\"GPU Memory usage before start: {get_gpu_memory_usage()} MB\")\n",
    "normalizer=joblib.load(filename_4_scalingfunction)\n",
    "\n",
    "#model.eval()\n",
    "timely=[]\n",
    "start2 = time.process_time()\n",
    "num=1000\n",
    "\n",
    "\n",
    "#loaded_model.load_state_dict(torch.load('lstm_model_best.pth'))\n",
    "#loaded_model.eval()\n",
    "\n",
    "# Run inference\n",
    "# Convert the outputs to numpy array if needed\n",
    "#test_outputs = test_outputs.numpy()\n",
    "#model.eval()\n",
    "\n",
    "for i in range(num):       \n",
    "\n",
    "    norm_test_features=scale_3D_inference(test_data,normalizer) # data_test_features \n",
    "    # Convert test numpy array to PyTorch tensor\n",
    "    test_data_tensor = torch.tensor(norm_test_features, dtype=torch.float32)\n",
    "    #Predict the residual using the model\n",
    "    with torch.no_grad():\n",
    "        test_outputs = loaded_model(test_data_tensor)\n",
    "    \n",
    "\n",
    "    # print(time.process_time() - start)\n",
    "    # print(f\"Computational time for {num}  no loading, s\", time.process_time() - start2)\n",
    "    \n",
    "# #Plot the residual\n",
    "\n",
    "# Check memory usage and time\n",
    "print(time.process_time() - start2)\n",
    "print(f\"Mean Time: s, {(time.process_time() - start)/num}\")\n",
    "print(f\"CPU Memory usage: {get_cpu_memory_usage() / (1024 ** 2):.2f} MB\")\n",
    "print(f\"GPU Memory usage: {get_gpu_memory_usage()} MB\")\n",
    "\n",
    "\n",
    "print(norm_test_features.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
